{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file is used for voice translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.8.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.8.0/en_core_web_sm-3.8.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.8.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "#Downloading required libraries:\n",
    "#pip install gtts\n",
    "#!pip install googletrans==4.0.0-rc1 ##used deep translator instead of this one, can avoid this one\n",
    "#!pip install pydub\n",
    "#!brew install ffmpeg\n",
    "#!pip install playsound\n",
    "#!brew install portaudio\n",
    "#!pip install pyaudio\n",
    "#!pip3 install PyObjC\n",
    "#!pip install SpeechRecognition\n",
    "#!pip install openai-whisper\n",
    "#!pip install deep-translator\n",
    "#!pip install spacy\n",
    "#!python3 -m spacy download en_core_web_sm\n",
    "#!pip install schedule\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code is used for live audio translation during a call with patient.\n",
    "Considering the patient to be on call with doctor and the doctor has put the speaker ON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Patient's Turn (Speaking Local Language) ---\n",
      "Listening (te)... Speak now!\n",
      "Could not understand audio. Please speak again.\n",
      "Listening (te)... Speak now!\n",
      "Recognized (te): హలో ఎలా ఉన్నారు\n",
      "Translated (te → en): Hello how are you\n",
      "\n",
      "--- Doctor's Turn (Reply in English) ---\n",
      "Listening (en)... Speak now!\n",
      "Could not understand audio. Please speak again.\n",
      "Listening (en)... Speak now!\n",
      "Recognized (en): Hi how are you\n",
      "Translated (en → te): హాయ్ మీరు ఎలా ఉన్నారు\n",
      "\n",
      "--- Speaking Translation to Patient ---\n",
      "\n",
      "--- Patient's Turn (Speaking Local Language) ---\n",
      "Listening (te)... Speak now!\n",
      "Could not understand audio. Please speak again.\n",
      "Listening (te)... Speak now!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Patient\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Turn (Speaking Local Language) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 46\u001b[0m     patient_text \u001b[38;5;241m=\u001b[39m \u001b[43mrecognize_speech\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mte\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Telugu input\u001b[39;00m\n\u001b[1;32m     47\u001b[0m     translated_to_english \u001b[38;5;241m=\u001b[39m translate_text(patient_text, src_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mte\u001b[39m\u001b[38;5;124m\"\u001b[39m, dest_lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Doctor\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms Turn (Reply in English) ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 17\u001b[0m, in \u001b[0;36mrecognize_speech\u001b[0;34m(lang)\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mListening (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)... Speak now!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     recognizer\u001b[38;5;241m.\u001b[39madjust_for_ambient_noise(source)\n\u001b[0;32m---> 17\u001b[0m     audio \u001b[38;5;241m=\u001b[39m \u001b[43mrecognizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlisten\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# Recognize speech\u001b[39;00m\n\u001b[1;32m     20\u001b[0m     text \u001b[38;5;241m=\u001b[39m recognizer\u001b[38;5;241m.\u001b[39mrecognize_google(audio, language\u001b[38;5;241m=\u001b[39mlang)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/speech_recognition/__init__.py:460\u001b[0m, in \u001b[0;36mRecognizer.listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    458\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_listen(source, timeout, phrase_time_limit, snowboy_configuration, stream)\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 460\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m result:\n\u001b[1;32m    461\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m a\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/speech_recognition/__init__.py:530\u001b[0m, in \u001b[0;36mRecognizer._listen\u001b[0;34m(self, source, timeout, phrase_time_limit, snowboy_configuration, stream)\u001b[0m\n\u001b[1;32m    527\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m phrase_time_limit \u001b[38;5;129;01mand\u001b[39;00m elapsed_time \u001b[38;5;241m-\u001b[39m phrase_start_time \u001b[38;5;241m>\u001b[39m phrase_time_limit:\n\u001b[1;32m    528\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 530\u001b[0m buffer \u001b[38;5;241m=\u001b[39m \u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCHUNK\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(buffer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m: \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# reached end of the stream\u001b[39;00m\n\u001b[1;32m    532\u001b[0m frames\u001b[38;5;241m.\u001b[39mappend(buffer)\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/speech_recognition/__init__.py:191\u001b[0m, in \u001b[0;36mMicrophone.MicrophoneStream.read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread\u001b[39m(\u001b[38;5;28mself\u001b[39m, size):\n\u001b[0;32m--> 191\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyaudio_stream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/pyaudio/__init__.py:570\u001b[0m, in \u001b[0;36mPyAudio.Stream.read\u001b[0;34m(self, num_frames, exception_on_overflow)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_input:\n\u001b[1;32m    568\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNot input stream\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    569\u001b[0m                   paCanNotReadFromAnOutputOnlyStream)\n\u001b[0;32m--> 570\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_stream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_frames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mexception_on_overflow\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from deep_translator import GoogleTranslator\n",
    "from gtts import gTTS\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "import tempfile\n",
    "\n",
    "# Initialize Recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "def recognize_speech(lang=\"auto\"):\n",
    "    \"\"\"Captures and recognizes speech using Google API, waits for clear input\"\"\"\n",
    "    while True:  # Keep retrying until speech is clear\n",
    "        with sr.Microphone() as source:\n",
    "            print(f\"Listening ({lang})... Speak now!\")\n",
    "            recognizer.adjust_for_ambient_noise(source)\n",
    "            audio = recognizer.listen(source)\n",
    "        try:\n",
    "            # Recognize speech\n",
    "            text = recognizer.recognize_google(audio, language=lang)\n",
    "            print(f\"Recognized ({lang}): {text}\")\n",
    "            return text  # Return only when speech is recognized clearly\n",
    "        except sr.UnknownValueError:\n",
    "            print(\"Could not understand audio. Please speak again.\")\n",
    "        except sr.RequestError:\n",
    "            print(\"API unavailable. Check internet.\")\n",
    "\n",
    "def translate_text(text, src_lang, dest_lang):\n",
    "    \"\"\"Translates text between languages\"\"\"\n",
    "    translator = GoogleTranslator(source=src_lang, target=dest_lang)\n",
    "    translated_text = translator.translate(text)\n",
    "    print(f\"Translated ({src_lang} → {dest_lang}): {translated_text}\")\n",
    "    return translated_text\n",
    "\n",
    "def text_to_speech(text, lang):\n",
    "    \"\"\"Converts text to speech and plays it\"\"\"\n",
    "    tts = gTTS(text=text, lang=lang)\n",
    "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".mp3\") as fp:\n",
    "        tts.save(fp.name)\n",
    "        audio = AudioSegment.from_file(fp.name, format=\"mp3\")\n",
    "        play(audio)\n",
    "\n",
    "# Main Loop: Real-Time Translation Between Patient & Doctor\n",
    "while True:\n",
    "    print(\"\\n--- Patient's Turn (Speaking Local Language) ---\")\n",
    "    patient_text = recognize_speech(lang=\"te\")  # Telugu input\n",
    "    translated_to_english = translate_text(patient_text, src_lang=\"te\", dest_lang=\"en\")\n",
    "    print(\"\\n--- Doctor's Turn (Reply in English) ---\")\n",
    "    doctor_text = recognize_speech(lang=\"en\")  # English input\n",
    "    translated_to_patient = translate_text(doctor_text, src_lang=\"en\", dest_lang=\"te\")\n",
    "    print(\"\\n--- Speaking Translation to Patient ---\")\n",
    "    text_to_speech(translated_to_patient, lang=\"te\")  # Doctor's response in Telugu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following code utilises Natural Language Processing for extracting content from doctors voice regarding prescription and converting to text. The output text can be sent as an input to any SMS tool for sending the message to patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T14:38:48.231662Z",
     "start_time": "2025-03-02T14:38:48.047494Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doctor, please dictate the prescription...\n",
      "Recognized Speech: hi please take paracetamol at 9:00 a.m. everyday\n",
      "Extracted Prescription: {'paracetamol': {'dosage': 'Unknown', 'times': []}, 'a.m.': {'dosage': 'Unknown', 'times': []}, 'everyday': {'dosage': 'Unknown', 'times': []}}\n",
      "Reminder system is running... (Press Ctrl+C to stop)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 95\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     94\u001b[0m     schedule\u001b[38;5;241m.\u001b[39mrun_pending()\n\u001b[0;32m---> 95\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Prevent excessive CPU usage\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# set remainders\n",
    "import speech_recognition as sr\n",
    "import spacy\n",
    "import schedule\n",
    "import time\n",
    "from gtts import gTTS\n",
    "from playsound import playsound\n",
    "import tempfile\n",
    "\n",
    "nlp = spacy.load('en_core_web_sm')  # Loading spacy\n",
    "\n",
    "# mapping for time words to actual times\n",
    "TIME_MAPPING = {\n",
    "    \"morning\": \"08:00\",\n",
    "    \"afternoon\": \"14:00\",\n",
    "    \"evening\": \"18:00\",\n",
    "    \"night\": \"21:00\",\n",
    "    \"before breakfast\": \"07:30\",\n",
    "    \"after breakfast\": \"09:00\",\n",
    "    \"before lunch\": \"12:30\",\n",
    "    \"after lunch\": \"13:30\",\n",
    "    \"before dinner\": \"19:30\",\n",
    "    \"after dinner\": \"20:30\",\n",
    "    \"every 6 hours\": [\"06:00\", \"12:00\", \"18:00\", \"00:00\"], \n",
    "}\n",
    " \n",
    "recognizer = sr.Recognizer() # Initializing speech recognizer\n",
    "\n",
    "def recognize_speech():\n",
    "    \"\"\"Captures and converts doctor's speech to text\"\"\"\n",
    "    with sr.Microphone() as source:\n",
    "        print(\"Doctor, please dictate the prescription...\")\n",
    "        recognizer.adjust_for_ambient_noise(source)\n",
    "        audio = recognizer.listen(source)\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio)\n",
    "        print(f\"Recognized Speech: {text}\")\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        print(\"Could not understand audio.\")\n",
    "        return None\n",
    "    except sr.RequestError:\n",
    "        print(\"Speech service unavailable.\")\n",
    "        return None\n",
    "\n",
    "def extract_medicine_schedule(text):\n",
    "    \"\"\"Extracts medicines, dosages, and schedules using NLP\"\"\"\n",
    "    medicines = {}\n",
    "    doc = nlp(text.lower())\n",
    "\n",
    "    current_medicine = None\n",
    "    for token in doc:\n",
    "        # Detect medicine name (Assumption: Proper nouns or words in medical vocabulary)\n",
    "        if token.pos_ in [\"NOUN\", \"PROPN\"] and len(token.text) > 2:\n",
    "            current_medicine = token.text\n",
    "            medicines[current_medicine] = {\"dosage\": \"Unknown\", \"times\": []}\n",
    "        # Detect dosage\n",
    "        if token.like_num or \"mg\" in token.text or \"ml\" in token.text or \"tablet\" in token.text:\n",
    "            if current_medicine:\n",
    "                medicines[current_medicine][\"dosage\"] = token.text\n",
    "        # Detect time expressions\n",
    "        for key, time_value in TIME_MAPPING.items():\n",
    "            if key in token.text:\n",
    "                if isinstance(time_value, list):  # handles repetitive values\n",
    "                    medicines[current_medicine][\"times\"].extend(time_value)\n",
    "                else:\n",
    "                    medicines[current_medicine][\"times\"].append(time_value)\n",
    "    return medicines\n",
    "\n",
    "def schedule_reminders(medicines):\n",
    "    \"\"\"Schedules medicine intake reminders\"\"\"\n",
    "    for medicine, details in medicines.items():\n",
    "        for time_slot in details[\"times\"]:\n",
    "            schedule.every().day.at(time_slot).do(send_notification, medicine, time_slot)\n",
    "\n",
    "def send_notification(medicine_name, time_slot):\n",
    "    \"\"\"Actual notification push\"\"\"\n",
    "    message = f\"Reminder: Take your {medicine_name} now ({time_slot}).\"\n",
    "    print(message)\n",
    "    tts = gTTS(text=message, lang=\"en\") # converts text to voice message for notification\n",
    "    with tempfile.NamedTemporaryFile(delete=True, suffix=\".mp3\") as fp:\n",
    "        tts.save(fp.name)\n",
    "        playsound(fp.name)\n",
    "\n",
    "# Main process\n",
    "spoken_text = recognize_speech()\n",
    "if spoken_text:\n",
    "    extracted_data = extract_medicine_schedule(spoken_text)\n",
    "    print(\"Extracted Prescription:\", extracted_data)\n",
    "    schedule_reminders(extracted_data)\n",
    "\n",
    "    print(\"Reminder system is running... (Press Ctrl+C to stop)\")\n",
    "    while True:\n",
    "        schedule.run_pending()\n",
    "        time.sleep(1)  # Prevent excessive CPU usage\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
